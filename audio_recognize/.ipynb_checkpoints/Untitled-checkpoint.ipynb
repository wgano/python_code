{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fde4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T15:48:38.584402Z",
     "start_time": "2023-11-05T15:48:35.679597Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请说话...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16564\\2890811033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"请说话...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    489\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m                     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\pyaudio\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    568\u001b[0m                 raise IOError(\"Not input stream\",\n\u001b[0;32m    569\u001b[0m                               paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[1;33m             return pa.read_stream(self._stream, num_frames,\n\u001b[0m\u001b[0;32m    571\u001b[0m                                   exception_on_overflow)\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# 创建一个Recognizer对象\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# 使用麦克风录制声音\n",
    "with sr.Microphone() as source:\n",
    "    print(\"请说话...\")\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "try:\n",
    "    # 使用Google Web Speech API进行语音识别\n",
    "    text = recognizer.recognize_google(audio, language=\"zh-CN\")\n",
    "    print(\"识别结果: \" + text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"无法识别声音\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"请求出错: {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf3092",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-05T15:48:42.243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按住 'k' 键并开始说话...\n",
      "正在识别...\n",
      "无法识别声音\n",
      "按住 'k' 键并开始说话...\n",
      "正在识别...\n",
      "识别结果: 打开浏览\n",
      "按住 'k' 键并开始说话...\n",
      "正在识别...\n",
      "识别结果: 打开浏览器\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\anaconda\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"F:\\anaconda\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"F:\\anaconda\\lib\\site-packages\\keyboard\\_generic.py\", line 58, in process\n",
      "    if self.pre_process_event(event):\n",
      "  File \"F:\\anaconda\\lib\\site-packages\\keyboard\\__init__.py\", line 213, in pre_process_event\n",
      "    key_hook(event)\n",
      "  File \"F:\\anaconda\\lib\\site-packages\\keyboard\\__init__.py\", line 510, in <lambda>\n",
      "    return hook_key(key, lambda e: e.event_type == KEY_UP or callback(e), suppress=suppress)\n",
      "  File \"C:\\Users\\24231\\AppData\\Local\\Temp\\ipykernel_16564\\3281984541.py\", line 38, in <lambda>\n",
      "  File \"C:\\Users\\24231\\AppData\\Local\\Temp\\ipykernel_16564\\3281984541.py\", line 29, in listen_for_speech\n",
      "  File \"F:\\anaconda\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"F:\\anaconda\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "FileNotFoundError: [WinError 2] 系统找不到指定的文件。\n"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "import speech_recognition as sr\n",
    "import subprocess\n",
    "\n",
    "# 创建一个Recognizer对象\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# 设置一个全局变量来跟踪是否正在按住指定的按键\n",
    "is_listening = False\n",
    "\n",
    "def listen_for_speech(key):\n",
    "    global is_listening\n",
    "\n",
    "    if not is_listening:\n",
    "        print(\"按住 '{}' 键并开始说话...\".format(key))\n",
    "        is_listening = True\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "        is_listening = False\n",
    "        print(\"正在识别...\")\n",
    "        \n",
    "        try:\n",
    "            # 使用Google Web Speech API进行语音识别\n",
    "            text = recognizer.recognize_google(audio,language=\"zh-CN\")\n",
    "            print(\"识别结果: \" + text)\n",
    "\n",
    "            # 根据识别结果执行相应的操作\n",
    "            if \"打开浏览器\" in text:\n",
    "                subprocess.Popen([\"edge.exe\"])  # 用你的浏览器命令替换\"your_browser_command_here\"\n",
    "            # 可以添加其他操作的条件语句\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"无法识别声音\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"请求出错: {0}\".format(e))\n",
    "\n",
    "# 配置按键监听\n",
    "keyboard.on_press_key(\"k\", lambda event: listen_for_speech(event.name))\n",
    "\n",
    "# 创建一个麦克风对象\n",
    "with sr.Microphone() as source:\n",
    "    while True:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9177dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T15:55:09.058508Z",
     "start_time": "2023-11-05T15:55:07.984049Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CreateModel failed with 'Failed to initialize memory mapped model.' (0x3000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21580\\292567871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 初始化DeepSpeech模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"deepspeech-0.9.3-models.pbmm\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 读取音频文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\lib\\site-packages\\deepspeech\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCreateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CreateModel failed with '{}' (0x{:X})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mErrorCodeToErrorMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CreateModel failed with 'Failed to initialize memory mapped model.' (0x3000)"
     ]
    }
   ],
   "source": [
    "import deepspeech\n",
    "import wave\n",
    "\n",
    "# 初始化DeepSpeech模型\n",
    "model_path = \"deepspeech-0.9.3-models.pbmm\"\n",
    "model = deepspeech.Model(model_path)\n",
    "\n",
    "# 读取音频文件\n",
    "audio_file = \"sample.wav\"\n",
    "\n",
    "# 打开音频文件并进行识别\n",
    "with wave.open(audio_file, 'rb') as wf:\n",
    "    audio_data = wf.readframes(wf.getnframes())\n",
    "    text = model.stt(audio_data)\n",
    "    print(\"识别结果: \" + text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b4c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
