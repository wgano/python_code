{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4822b7",
   "metadata": {},
   "source": [
    "# 数值最优化方法python代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49f8d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:17.338846Z",
     "start_time": "2023-10-04T10:12:15.447664Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入需要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3284f5b",
   "metadata": {},
   "source": [
    "## 2.无约束最优化方法的基本结构\n",
    "**无约束最优化算法的基本结构:**\n",
    "\n",
    "1. 给定初始点$x_{0}\\in R^{n},k:=0$\n",
    "2. 如果此时满足终止准则,输出结果否则下一步\n",
    "3. 确定下降方向$d_{k}$\n",
    "4. 确定步长$\\alpha_{k}$使$f(x_{k}+\\alpha_{k}d_{k})<f(x_{k})$\n",
    "5. 令$x_{k+1}:=x_{k}+\\alpha_{k}d_{k},k:=k+1$ 转第二步\n",
    "\n",
    "总之就是一个函数确定一个方向让他可以变小,在确定一个不长不短的步长"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a864da4",
   "metadata": {},
   "source": [
    "**判断算法的收敛速度:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3d87f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:29:19.410782Z",
     "start_time": "2023-10-04T10:29:19.395966Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#求范数\n",
    "def norm(x,n):\n",
    "    return ((sum(x**n))**(1/n))\n",
    "\n",
    "#判断线性收敛和超线性收敛\n",
    "def linear_converge(opt_fun,x_,k):#给一个函数opt_fun传入一个点返回下一个迭代点,传入解x_和迭代次数k,这里k要趋近于正无穷,我们就给一个大一点的数\n",
    "    for i in range(k):\n",
    "        a = opt_fun(a)#获得第k次迭代的点\n",
    "    b = norm(opt_fun(a)-x_,2)/norm(a-x_,2)#将第k+1次迭代的点减解的 二范数 除以 第k次迭代的点减解的 二范数\n",
    "    if b == 0:\n",
    "        return \"sup_linear\"#超线性收敛\n",
    "    elif b>0 and b<1:\n",
    "        return \"linear_converge\"#线性收敛\n",
    "    else:\n",
    "        return \"no_linear_congverge\"#非线性收敛\n",
    "\n",
    "#判断二阶收敛\n",
    "def double_converge(opt_fun,x_,k):#同上\n",
    "    for i in range(k):\n",
    "        a = opt_fun(a)#获得第k次迭代的点\n",
    "    b = norm(opt_fun(a)-x_,2)/norm(a-x_,2)**2#将第k+1次迭代的点减解的 二范数 除以 第k次迭代的点减解的 二范数 的平方\n",
    "    if b>0 and b<1:\n",
    "        return \"double_converge\"#二阶收敛\n",
    "    else:\n",
    "        return \"no_double_congverge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636da8d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:41.004148Z",
     "start_time": "2023-10-04T10:12:40.965399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.881943016134134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdffe832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:26.398199Z",
     "start_time": "2023-10-04T10:12:26.387733Z"
    },
    "scrolled": true
   },
   "source": [
    "## 最速下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f36e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_pri(gfun,x,epsilon):\n",
    "    if norm(gfun(x),2)<epsilon:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def odim_pre_lsearch(gfun,d_k):\n",
    "    pass\n",
    "def SDS(fun,gfun,x,epsilon):\n",
    "    if end_pri(gfun,x,epsilon):\n",
    "        return x\n",
    "    else:\n",
    "        d_k = -1*gfun(x)\n",
    "        a_k = odim_pre_lsearch(gfun,d_k)\n",
    "        x=x+a_k*d_k\n",
    "        SDS(fun,gfun,x,epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
